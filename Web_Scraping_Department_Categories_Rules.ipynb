{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Web Scraping Department Categories.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3_QBM-c-PRO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# author: Simon Zhu\n",
        "# The data to be scraped is from UVA's unofficial course website \"Lou's List\",\n",
        "# created by Professor Lou Bloomfield.\n",
        "# The website is https://rabi.phys.virginia.edu/mySIS/CS2\n",
        "# You are welcome to freely use the result of this small project.\n",
        "\n",
        "# Import libraries\n",
        "import requests\n",
        "import urllib.request\n",
        "import time\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Set the URL you want to webscrape from\n",
        "url = 'https://rabi.phys.virginia.edu/mySIS/CS2/'\n",
        "\n",
        "# Connect to the URL\n",
        "response = requests.get(url)\n",
        "\n",
        "# Parse HTML and save to BeautifulSoup objectÂ¶\n",
        "soup = BeautifulSoup(response.text, \"html.parser\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lR0iKnfP5Ws3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# now from the Internet scrape the bijective relationship between a subject name and its mnemonic \n",
        "# (e.g: Computer Science to CS)\n",
        "url_3 = \"https://rabi.phys.virginia.edu/mySIS/CS2/page.php?Semester=1198&Type=Group&Group=CS\"\n",
        "res_3 = requests.get(url_3)\n",
        "soup_3 = BeautifulSoup(res_3.text, \"html.parser\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7OOE1QB7LU_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "department = soup_3.find(\"td\",{\"class\":\"UnitName\"})\n",
        "regex = re.compile('[^A-Z]')\n",
        "mne_dict ={}\n",
        "while department:\n",
        "  mne = department.find_next(\"td\",{\"class\":\"CourseNum\"})\n",
        "  mne_text = mne.get_text()[1:5]\n",
        "  mne_dict[department.get_text()] = regex.sub('',mne_text)\n",
        "  department = mne.find_next(\"td\",{\"class\":\"UnitName\"})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHMv0Jp3nUex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# a method that finds the subjects in each department\n",
        "def find_subs(parser,d_dict,idx):\n",
        "  subjects = parser.find_all('td',{\"class\":\"UnitName\"})\n",
        "  out = []\n",
        "  # add the corresponding mnemonic to the list\n",
        "  for s in subjects: out.append(mne_dict[s.get_text()])\n",
        "  d_dict[idx] = out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zz56r2kht-s2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# a method that finds the departments under each categories and then furthermore \n",
        "# find the subjects\n",
        "def find_departs(cat,cat_dict,cat_idx):\n",
        "  # find all the departments in this category\n",
        "  departs=cat.find_all('td',{\"class\":\"IndexTable4\"})\n",
        "  d_dict = {}\n",
        "  for depart in departs:\n",
        "    idx = depart.get_text()\n",
        "#     print(idx)\n",
        "    if depart.a: url_2 = url + depart.a['href']\n",
        "    res = requests.get(url_2)\n",
        "    b_soup = BeautifulSoup(res.text, \"html.parser\")\n",
        "    # jump to the corresponding url and then find all the subjects in that department\n",
        "    find_subs(b_soup,d_dict,idx)\n",
        "    cat_dict[cat_idx] = d_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWSK33D4sYuf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create the final dictionary that has all the information\n",
        "num_cats = 7\n",
        "cat = soup.find('h3')\n",
        "cat_dict={}\n",
        "for i in range(num_cats):\n",
        "  a_table = cat.find_next('table')\n",
        "#   print(cat.get_text())\n",
        "  find_departs(a_table,cat_dict,cat.get_text())\n",
        "  cat = a_table.find_next('h3')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WC8B8oh2BEGc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cat_dict"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}